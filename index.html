<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"the-fleetinglove.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.13.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="FleetingSmile Blog">
<meta property="og:url" content="http://the-fleetinglove.github.io/index.html">
<meta property="og:site_name" content="FleetingSmile Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="XS">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://the-fleetinglove.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>FleetingSmile Blog</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FleetingSmile Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>Home</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>About</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="XS"
      src="/images/IMG_0045.jpg">
  <p class="site-author-name" itemprop="name">XS</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--To%20Fit%20or%20Not%20to%20Fit%20Model-based%20Face%20Reconstruction%20and%20Occlusion%20Segmentation%20from%20Weak%20Supervision/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--To%20Fit%20or%20Not%20to%20Fit%20Model-based%20Face%20Reconstruction%20and%20Occlusion%20Segmentation%20from%20Weak%20Supervision/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-24 15:40:30" itemprop="dateCreated datePublished" datetime="2022-09-24T15:40:30+08:00">2022-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-12 16:47:49" itemprop="dateModified" datetime="2022-05-12T16:47:49+08:00">2022-05-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="论文笔记–To-Fit-or-Not-to-Fit-Model-based-Face-Reconstruction-and-Occlusion-Segmentation-from-Weak-Supervision"><a href="#论文笔记–To-Fit-or-Not-to-Fit-Model-based-Face-Reconstruction-and-Occlusion-Segmentation-from-Weak-Supervision" class="headerlink" title="论文笔记–To Fit or Not to Fit: Model-based Face Reconstruction and Occlusion Segmentation from Weak Supervision"></a><em><strong>论文笔记–To Fit or Not to Fit: Model-based Face Reconstruction and Occlusion Segmentation from Weak Supervision</strong></em></h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h2><p>​        由于遮挡物的剧烈的可变性，遮挡下的人脸重建极具挑战性。目前最成功的方法是通过逆向渲染来拟合3D人脸模型，并假设遮挡物给定分割，以此避免拟合遮挡物。然而，训练一个遮挡分割模型需要大量的注释数据。在这项工作中，我们介绍了一种基于模型的 3D 人脸重建方法，该方法对遮挡具有高度鲁棒性，但不需要任何遮挡注释进行训练。在我们的方法中，我们利用了生成人脸模型只能合成人脸而不是遮挡物的事实。我们使用此属性来指导遮挡分割网络的决策过程并完成无监督训练。目<strong>前主要挑战是模型拟合和遮挡分割相互依赖，需要共同推理。</strong>CelebA-HQ、AR 数据库和 Now Challenge 的定性和定量实验表明，所提出的方法在遮挡下实现了最先进的 3D 人 脸重建。此外，尽管在没有任何遮挡注释的情况下进行了训练，但分割网络仍能准确定位遮挡。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><strong>介绍</strong></h2><p>​        单目3D人脸重建旨在估计人脸的姿态、形状和反照率，以及场景的光照条件和相机参数。 从单个图像中解决所有这些因素是一个不适定问题。面部自动编码器面临的一个主要挑战是在野外环境下模型的性能仍然受到诸如遮挡，极端照明和姿势等因素限制。遮挡导致的一个核心问题是人脸模型会拟合被遮挡的人脸区域，导致重建的人脸失真。因此，一个遮挡的鲁棒的3D人脸重建问题就是去决定一张图像中哪些像素是需要去拟合，哪些像素是不需要去拟合的。</p>
<p>​        在本文的工作中，设计了一种基于模型的人脸重建方法，该方法具有高度的遮挡鲁棒性，不需要任何的人工遮挡注释。特别地，本文提出以一种合作的方式去训练一个面部自编码器和一个分割网络。分割网络决定人脸模型是否需要拟合某一像素的问题，以便人脸重建不受遮挡影响。分割网络采用无监督的方式去训练分割网络，利用了生成的人脸模型只能合成人脸而不能合成遮挡的事实。同时可以利用目标原始图像和渲染生成图像之间的差异作为监督信号来指导分割网络的训练。反过来，人脸重建网络通过使用来自分割网络的预测在拟合期间掩盖被遮挡的像素，从而对遮挡具有鲁棒性。这也导致了协同效应，遮挡分割引导面部自编码器拟合易于分类为面部区域的图像区域，改进的人脸拟合反过来又使得分割网络能够改进其预测。</p>
<p>​       训练过程遵循EM算法的核心思想，通过在给定当前分割掩码估计的情况下训练面部自编码器和随后基于当前 3D 面部重建训练分割网络之间交替进行。分割网络的无监督训练是通过在估计的遮挡掩码下正则化和保留目标图像和重建图像之间的相似性来实现的，通过引入了几个损失来实现这一点。设计的模型在三份数据集进行验证，分别是<strong>CelebA-HQ, AR, NoW challenge</strong>。</p>
<p>​        总之，我们在本文中做出了以下贡献：</p>
<ol>
<li> 实现一种基于模型的 3D 人脸重建方法，该方法具有高度鲁棒的遮挡，无需任何人工遮挡注释。</li>
<li> 设计的模型在遮挡下的 3D 人脸重建中实现了SOTA，并在野外图像上提供了面部遮挡掩码的准确估计。</li>
</ol>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a><strong>方法</strong></h2><p>​        本文的目标是由严重遮挡的单一图片重建出鲁棒的3D人脸。为解决该问题，本文将基于模型的人脸自动编码器 𝑅 与分割网络 𝑆 集成在一起，并在它们之间产生协同作用。分割掩码在模型拟合期间消除遮挡的估计，使重建网络对遮挡具有鲁棒性。重建的结果给分割网络提供了参考，促使分割网络的准确性提升。</p>
<p><img src="https://gitee.com/Forever_XS/markdown_paper_picture/raw/master/blog_casia/image-20220509144350144.png" alt="image-20220509144350144"></p>
<p>​        </p>
<h5 id="Training-the-segmentation-network"><a href="#Training-the-segmentation-network" class="headerlink" title="Training the segmentation network"></a>Training the segmentation network</h5><p>​        在训练分割网络时，人脸自编码器的参数是固定的，只优化分割网络。我们没有寻找标记数据，而是提出了四种损失来增强图像之间的内在相似性。 每个损失都可以包括指示面部或相反的像素。损失在感知级别或像素级别上起作用，以充分利用视觉线索。分割网络训练时的四种损失如下：</p>
<p><img src="https://gitee.com/Forever_XS/markdown_paper_picture/raw/master/blog_casia/image-20220509151017598.png" alt="image-20220509151017598"></p>
<p>​          除了上述四种损失外，还添加正则化项损失$L_{bin}=-\sum_x(M(x)-0.5)^2$来鼓励面部掩码是二值化分布（0或1）。总体损失函数式如下，其中$\eta_1=15\quad\eta_2=3\quad\eta_3=0.5\quad\eta_4=2.5\quad\eta_5=10$<br>$$<br>L_S=\eta_1L_{neighbor}+\eta_2L_{dist}+\eta_3L_{area}+\eta_4L_{presv}+\eta_5L_{bin}<br>$$</p>
<h5 id="Training-the-face-autoencoder"><a href="#Training-the-face-autoencoder" class="headerlink" title="Training the face autoencoder"></a>Training the face autoencoder</h5><p>​          训练面部自编码器网络时，冻结分割网络参数。训练损失函数如下：</p>
<img src="https://gitee.com/Forever_XS/markdown_paper_picture/raw/master/blog_casia/image-20220509155639300.png" alt="image-20220509155639300" style="zoom: 67%;" />

<h5 id="Unsupervised-Initialization"><a href="#Unsupervised-Initialization" class="headerlink" title="Unsupervised Initialization"></a>Unsupervised Initialization</h5><p>​        使用遮挡的鲁棒损失生成初级掩码：</p>
<p><img src="https://gitee.com/Forever_XS/markdown_paper_picture/raw/master/blog_casia/image-20220509160342837.png" alt="image-20220509160342837"></p>
<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>​       encoder采用ResNet50，segmentation network采用UNet。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Regressing%20Robust%20and%20Discriminative%203D%20Morphable%20Models%20with%20a%20very%20Deep%20Neural%20Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Regressing%20Robust%20and%20Discriminative%203D%20Morphable%20Models%20with%20a%20very%20Deep%20Neural%20Network/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-24 15:40:30" itemprop="dateCreated datePublished" datetime="2022-09-24T15:40:30+08:00">2022-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-05-12 16:48:04" itemprop="dateModified" datetime="2022-05-12T16:48:04+08:00">2022-05-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="论文笔记–Regressing-Robust-and-Discriminative-3D-Morphable-Models-with-a-very-Deep-Neural-Network"><a href="#论文笔记–Regressing-Robust-and-Discriminative-3D-Morphable-Models-with-a-very-Deep-Neural-Network" class="headerlink" title="论文笔记–Regressing Robust and Discriminative 3D Morphable Models with a very Deep Neural Network"></a><em><strong>论文笔记–Regressing Robust and Discriminative 3D Morphable Models with a very Deep Neural Network</strong></em></h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><em><strong>摘要</strong></em></h2><p>​        人脸的3维形状是易于区分的，但尽管如此，3维人脸仍很少用于人脸识别以及3维人脸数据经常是在受控环境下采集的。现有的方法在野外环境下对3D人脸的估计是不稳定的，会因同一主题的不同照片而发生变化，要么是过拟合，要么是过于通用（平均脸）。本文直接对输入图片处理，通过CNN回归3DMM的形状和纹理参数。<strong>本文通过提供一种生成大量标记示例的方法来克服所需的训练数据不足的问题</strong>。本文方法在<strong>MICC数据集</strong>实现SOTA效果，同时在人脸识别效果上也有成效，本文在人脸识别上是使用3D人脸形状作为表示，而不是其他系统使用的不透明深度特征向量。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><em><strong>介绍</strong></em></h2><p>​        3D人脸形状是易于辨识的，因为每个人的人脸形状是不同的，且人脸形状不受光照和纹理等因素影响。目前没有关于在野外环境中成功使用单视图人脸形状估计来识别具有挑战性的无约束人脸的方法。</p>
<img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220428131155413.png" alt="image-20220428131155413" style="zoom: 33%;" />

<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a><em><strong>方法</strong></em></h2><p>​        本文借助深度卷积神经网络来实现单张图片输入，回归得到3DMM面部形状参数。训练这样的CNN需要大量的带有正确3D面部形状标签的无约束面部数据。作者认为，之前没有将CNN用在三维人脸建模方面，主要是因为从二维图像重建三维人脸模型，我们需要回归高维的形状参数，这就要求非常深的网络，而训练非常深的网络又需要大量的训练数据，已知的三维人脸模型的训练集非常少。针对这一问题，作者提出利用一个对象的多姿态人脸图片生成准确率相当高的三维人脸形状（Automated 3D face reconstruction from multiple images using quality measures），然后把生成的模型作为训练集；对于鲁棒性和区别性的人脸形状怎么解决呢？借鉴二维空间中的深度卷积神经网络模型，而且模型还是现成的~</p>
<p>​        目前有三个主要现状认识：</p>
<ol>
<li><p>利用同一人脸的多辐图像可以得到精确的三维估计</p>
</li>
<li><p>正确的3D人脸形状的标签很少可以利用，而每个主体却是包含有多张照片的</p>
</li>
<li><p>深度神经网络能很好提取和区分人脸特征</p>
<p>方法概览：</p>
<p><img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220428131711825.png" alt="image-20220428131711825"></p>
</li>
</ol>
<h3 id="Generating-Training-data"><a href="#Generating-Training-data" class="headerlink" title="Generating Training data"></a><strong>Generating Training data</strong></h3><p>​        3DMM的表示采用的是BFM模型，模型数学含义表达式如公式(1)所示。其中$\alpha$和$\beta$分别表示形体和纹理参数，且都是99维的向量。<br>$$<br>S^{‘}=\hat{s}+W_S\alpha{\quad}{\quad}T^{‘}=\hat{t}+W_T\beta<br>$$<br>​        在中科院的CASIA WebFace dataset选定一张照片，利用CLNF做人脸检测，得到68个人脸关键点和该图片的置信度。将得到的关键点用来初始化估计人脸模型的姿态，该姿态用六个自由度表示， 三个自由度是旋转角度，三个是位移。 然后再优化3DMM的形状，纹理，姿态，光照和颜色，利用前人的方法解决定位误差。 一旦损失函数收敛，就得到的形状参数和纹理参数，这就是单个图像得到的3DMM估计。</p>
<p>​        一张图片的3DMM参数可以用公式(2)表示，N表示同一目标下所有视图数量，一个目标的一张视图的3DMM参数用$$\gamma_i$$表示，一个目标的3DMM参数用$\gamma$表示，$w_i$表示归一化后的置信度，如公式(3)所示。至此，每个CASIA数据集的目标对象都有一个合并好的3DMM参数向量$\gamma$相关联。<br>$$<br>γ_i=[\alpha_i,\beta_i]\quad i\in1..N\quad(2)<br>$$</p>
<p>$$<br>{\gamma}={\sum}<em>{i=1}^{N}{w_i·\gamma_i}\quad{and}\quad{\sum}</em>{i=1}^{N}w_i=1\quad(3)<br>$$</p>
<h3 id="Learning-to-regress-pooled-3DMM"><a href="#Learning-to-regress-pooled-3DMM" class="headerlink" title="Learning to regress pooled 3DMM"></a>Learning to regress pooled 3DMM</h3><p>​       使用之前生成的数据用于训练一个函数式，理想情况下，同一主题的不同照片通过该函数式回归得到的3DMM特征向量是一致的。本文采用了ResNet101，并经过人脸识别数据集的预训练。本文将该网络的最后一层全连接层进行修改，使其输出198维的3DMM特征向量$\gamma$。</p>
<p>​        本文是将CNN在CASIA数据集上进行微调，标签真值是之前生成的3DMM估计；同一目标对象的不同视角的图片共用一个3DMM形状参数；本文还采用了16层的VGG-Face架构进行训练验证，其结果稍逊于ResNet101。</p>
<p>​        3DMM向量属于多元高斯分布，均值在原点处，代表平均人脸。因此，在训练过程中采用标准的欧几里得损失会使得人脸模型太泛化，没有区别性。本文提出一种非对称欧拉损失，公式如下：其中$\gamma$是标签值，$\gamma_p$是预测值，$\lambda_1$和$\lambda_2$控制过度和不足的估计误差之间的平衡，$\lambda_1$和$\lambda_2$都等于1时就是传统的欧几里得损失。本文设定$\lambda_1$的值为1，$\lambda_2$的值为3，使模型更快摆脱欠拟合并且鼓励网络生成更真实的三维人脸模型。<br>$$<br>\ell(\gamma_p,\gamma)=\lambda_1·\underbrace{||\gamma^+-\gamma_{max}||^{2}<em>{2}}</em>{over-estimate}+\lambda_2·\underbrace{||\gamma_{p}^{+}-\gamma_{max}||^{2}<em>{2}}</em>{under-estimate}<br>$$</p>
<p>$$<br>{\gamma}^{+}{\doteq}{abs(\gamma)}{\doteq}{sign(\gamma)}·{\gamma}{\quad}{\quad}{\gamma^{+}<em>{p}{\doteq}{sign(\gamma)·\gamma_p}}{\quad}{\quad}{\gamma</em>{max}{\doteq}{max(\gamma^+,\gamma_{p}^{+})}}<br>$$</p>
<p>​         训练参数设置：SGD，batch_size: 144，momentum: 0.9，l2 weight decay: 0.0005，learning rate: 0.01 </p>
<p>​         3DMM参数直接通过CNN对输入图像回归得到，没有进行纹理渲染的优化，只为得到准确的形状。</p>
<h3 id="Parameter-based-3D-3D-recognition"><a href="#Parameter-based-3D-3D-recognition" class="headerlink" title="Parameter based 3D-3D recognition"></a>Parameter based 3D-3D recognition</h3><p>​        用余弦相似度来判断两个人脸三维模型是否相似，公式如下：<br>$$<br>s(\gamma_1,\gamma_2)=\frac{\gamma_{p1}·\gamma_{p2}^T}{||\gamma_{p1}||·||\gamma_{p2}||}<br>$$</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>评价指标：</p>
<p><img src="C:/Users/Admin/AppData/Roaming/Typora/typora-user-images/image-20220428132309766.png" alt="image-20220428132309766"></p>
<p>重建实验效果及对比：</p>
<p><img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220428132703834.png" alt="image-20220428132703834"></p>
<p>野外数据重建效果：</p>
<img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220428132730719.png" alt="image-20220428132730719" style="zoom: 67%;" />

<p><strong>END</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Learning%20an%20Animatable%20Detailed%203D%20Face%20Model%20from%20In-The-Wild%20Images/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Learning%20an%20Animatable%20Detailed%203D%20Face%20Model%20from%20In-The-Wild%20Images/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-24 15:40:30" itemprop="dateCreated datePublished" datetime="2022-09-24T15:40:30+08:00">2022-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-06-02 09:36:50" itemprop="dateModified" datetime="2022-06-02T09:36:50+08:00">2022-06-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="论文笔记–Learning-an-Animatable-Detailed-3D-Face-Model-from-In-The-Wild-Images"><a href="#论文笔记–Learning-an-Animatable-Detailed-3D-Face-Model-from-In-The-Wild-Images" class="headerlink" title="论文笔记–Learning an Animatable Detailed 3D Face Model from In-The-Wild Images"></a><em><strong>论文笔记–Learning an Animatable Detailed 3D Face Model from In-The-Wild Images</strong></em></h1><h2 id="现有不足"><a href="#现有不足" class="headerlink" title="现有不足"></a>现有不足</h2><p>现有的一些方法局限在于产生的人脸无法逼真地动画化，这些方法都没有模拟皱纹如何随表情变化。</p>
<p>部分方法是在高质量人脸扫描数据集下训练且在野外环境下的泛化能力不足，重建的人脸鲁棒性不足。</p>
<h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><ul>
<li>  第一种从<strong>野外图像</strong>去学习<strong>动画</strong>置换贴图的方法，通过多样情感参数可以合成较为可信的几何细节。</li>
<li>  提出<strong>细节一致性损失</strong>，将<strong>情感依赖</strong>的面部细节和<strong>身份依赖</strong>的面部细节区分开来。</li>
<li>  <strong>单张图片输入</strong>，重建的几何细节具有<strong>鲁棒性</strong>。</li>
<li>  SOTA结果</li>
<li>  代码开源</li>
</ul>
<h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><p>3DMM：采用FLAME模型；</p>
<p>外观模型：</p>
<p>相机模型：</p>
<p>光照模型：</p>
<p>纹理渲染：</p>
<h2 id="主体框架"><a href="#主体框架" class="headerlink" title="主体框架"></a>主体框架</h2><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Cross-modal%20Deep%20Face%20Normals%20with%20Deactivable%20Skip%20Connections/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Cross-modal%20Deep%20Face%20Normals%20with%20Deactivable%20Skip%20Connections/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-24 15:40:30" itemprop="dateCreated datePublished" datetime="2022-09-24T15:40:30+08:00">2022-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-07-08 17:02:24" itemprop="dateModified" datetime="2022-07-08T17:02:24+08:00">2022-07-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="论文笔记–Cross-modal-Deep-Face-Normals-with-Deactivable-Skip-Connections"><a href="#论文笔记–Cross-modal-Deep-Face-Normals-with-Deactivable-Skip-Connections" class="headerlink" title="论文笔记–Cross-modal Deep Face Normals with Deactivable Skip Connections"></a><em><strong>论文笔记–Cross-modal Deep Face Normals with Deactivable Skip Connections</strong></em></h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​        当下单目重建多采用数据驱动的策略，但是受限于真实标签数据的缺乏，导致这种方法很困难。本文提出一种跨模态网络架构，可以利用所有图像和法线数据（无论是否配对），通过encoder和decoder的跳跃连接实现面部细节在图像和法线维度上进行传递。本文方法的核心就是一个融合deactivable skip connection的模块，该方法通过相同的端到端架构集成了自动编码和图像到法线转换的功能。</p>
<h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><ul>
<li>一种可以利用跨模态学习从单张人脸图像估计法线的框架；</li>
<li>可停用的跳跃连接架构模式（deactivable skip connection）</li>
<li>SOTA效果</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220708143501613.png" alt="image-20220708143501613" style="zoom:50%;" />



<p>​      该架构允许利用成对或非成对的图像/法线数据进行图像到法线的转换（$I$-&gt;$\hat{N}$），在训练期间通过图像到图像（$I$-&gt;$\hat{I}$）和法线到法线（$N$-&gt;$\hat{N}$）的转换过程进行正则化。$E_I$到$D_N$的跳跃连接可以传递面部细节信息。</p>
<h5 id="deactivable-skip-connection："><a href="#deactivable-skip-connection：" class="headerlink" title="deactivable skip connection："></a>deactivable skip connection：</h5><p>![image-20220707185938605](论文笔记–Cross-modal Deep Face Normals with Deactivable Skip Connections.assets/image-20220707185938605.png)</p>
<p>在特征图从encoder到decoder传递过程中，这个skip connection可以选择开启或关闭。</p>
<p>在进行 normal-&gt;normal ($E_N$-&gt;$D_N$) 传递过程中，$D_N$的每一层输出$F_{D}^{n-i}=f(F_{D}^{n-i-1})$</p>
<p>在进行 image-&gt;normal（$E_I$-&gt;$D_N$）传递过程中，$D_N$的每一层输出$F_{D}^{n-i}$是由  前一层输出的$f(F_{D}^{n-i-1})$上和$F_E^i$同样通道数量的特征图，与$F_E^i$特征图进行element-wise max操作，得到新的特征图后和剩余通道数量的$f(F_{D}^{n-i-1})$特征图进行相加得到。</p>
<p>这样做允许在不发生传输操作时将信息从编码器传输到解码器，而不会降低性能，就像自编码器正常工作时一样。</p>
<h5 id="loss-function："><a href="#loss-function：" class="headerlink" title="loss function："></a>loss function：</h5><img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220708143717592.png" alt="image-20220708143717592" style="zoom: 80%;" />



<p>训练过程只能对一个模态进行输入，要么是法线图要么是原图。</p>
<ul>
<li>当有原图输入，同时也有图片和法线图的ground truth时，先进行normal to normal，再进行 image to normal，最后进行image to image。上述的两个loss值进行同样比重求和得到最终loss。</li>
<li>当只有images或者只有normals时，就只进行image to image或者normal to normal的传输过程。</li>
</ul>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><img src="论文笔记--Cross-modal Deep Face Normals with Deactivable Skip Connections.assets/image-20220708143803733.png" alt="image-20220708143803733" style="zoom:50%;" />

<img src="论文笔记--Cross-modal Deep Face Normals with Deactivable Skip Connections.assets/image-20220708144012178.png" alt="image-20220708144012178" style="zoom:67%;" />

<img src="论文笔记--Cross-modal Deep Face Normals with Deactivable Skip Connections.assets/image-20220708143915072.png" alt="image-20220708143915072" style="zoom:67%;" />

<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>跳跃连接为什么只用在$E_I$到$D_N$的过程，其他传输过程为什么不用跳跃连接</p>
<p>论文验证有列出3维人脸模型的重构效果，具体是怎么生成这个3维人脸的，method没有涉及这块，可能在验证实验部分有说。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Accurate%203D%20Face%20Reconstruction%20with%20Weakly-Supervised%20LearningFrom%20Single%20Image%20to%20Image%20Set/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/24/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0--Accurate%203D%20Face%20Reconstruction%20with%20Weakly-Supervised%20LearningFrom%20Single%20Image%20to%20Image%20Set/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-24 15:40:30" itemprop="dateCreated datePublished" datetime="2022-09-24T15:40:30+08:00">2022-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-07-12 11:48:57" itemprop="dateModified" datetime="2022-07-12T11:48:57+08:00">2022-07-12</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="论文笔记–Accurate-3D-Face-Reconstruction-with-Weakly-Supervised-Learning-From-Single-Image-to-Image-Set"><a href="#论文笔记–Accurate-3D-Face-Reconstruction-with-Weakly-Supervised-Learning-From-Single-Image-to-Image-Set" class="headerlink" title="论文笔记–Accurate 3D Face Reconstruction with Weakly-Supervised Learning:From Single Image to Image Set"></a><em><strong>论文笔记–Accurate 3D Face Reconstruction with Weakly-Supervised Learning:From Single Image to Image Set</strong></em></h1><h2 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1 摘要"></a><strong>1 摘要</strong></h2><p>​        最近，基于深度学习的3D人脸重建方法在质量和效率上都显现出可喜的成果。然而，深度神经网络的训练通常需要大量的数据，而具有真实3D人脸形状标签的人脸图像却很少。该文章提出一种深度3D人脸重建方法：</p>
<ol>
<li><p><em><strong>利用一个稳健的混合损失函数进行弱监督学习，该函数同时考虑了 image-level 和 perception-level 的鲁棒性</strong></em></p>
<p> <em><strong>（ image-level损失指的是重建的人脸模型渲染得到的图片和输入图片的像素值应尽可能一致；perception-level损失指的是重建的人脸模型渲染得到的图片和输入图片的内在特征应尽可能一致 ）</strong></em></p>
</li>
<li><p> <em><strong>利用不同图像的互补信息进行形状聚合，进行多图像人脸重建。</strong></em></p>
</li>
</ol>
<p>​        文章提出的方法快速，准确且对遮挡和大姿态的图像具有鲁棒性。该文章在MICC Florence 和 Facewarehouse数据集上进行实验论证，同时系统地与最近几年的15种方法进行对比，实验结果证明本文提出的方法展现出了目前最先进的性能。</p>
<p>​        Code (Pytorch): <a target="_blank" rel="noopener" href="https://github.com/sicxu/Deep3DFaceRecon_pytorch">https://github.com/sicxu/Deep3DFaceRecon_pytorch</a></p>
<h2 id="2-介绍"><a href="#2-介绍" class="headerlink" title="2 介绍"></a><strong>2 介绍</strong></h2><p>​        从非受限场景下的2D图像中忠实地恢复人脸的3D形状是一项具有挑战性的任务，并且具有许多应用，例如人脸识别，面部媒体操控，人脸动画等。最近，人们对使用CNN来实现单个图像重建 3D 人脸的兴趣激增，以代替使用复杂且要大量优化的传统方法。由于真实的3D人脸数据稀少，以往的许多方法都使用合成数据或者使用传统方法拟合的3D形状作为替代形状标签，但是这种做法会受到域差距和不准确的训练标签影响。</p>
<p>​        无监督学习的关键是一个可微的图像形成过程，它使用网络预测来渲染人脸图像，监督信号源于输入图像和渲染对应物之间的差异。该问题提出了混合级损失函数和一种新颖的基于肤色的光度误差注意策略，该方法对人脸遮挡问题有一定解决。该文章也在重点研究同一目标多图像的人脸重建问题。</p>
<p>​        该文章训练一个辅助网络。借助该网络回归得到承载身份的3D模型系数的置信度，并通过基于置信度的聚合获得最终的身份系数。它可以利用位姿差异更好地融合互补信息，学习更准确的3D形状。</p>
<p>​        该文章的主要两项贡献是：</p>
<ol>
<li><strong>提出一种基于 CNN 的单图像人脸重建方法，该方法利用混合级图像信息进行弱监督学习。改进的损失函数包括图像级损失和感知级损失。使用低维 3DMM 子空间，仍然能够胜过具有“无限制”3D 表示的现有技术。</strong></li>
<li><strong>提出一种用于多图像人脸重建聚合的新型形状置信度学习方法。置信预测子网也以弱监督方式进行训练，方法明显优于朴素聚合（例如形状平均）。</strong></li>
</ol>
<h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3 方法"></a><strong>3 方法</strong></h2><h3 id="3-1-整体架构"><a href="#3-1-整体架构" class="headerlink" title="3.1 整体架构"></a><strong>3.1 整体架构</strong></h3><p><img src="https://gitee.com/Forever_XS/markdown_paper_picture/raw/master/blog_casia/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16511301992429.png" alt="img"></p>
<h3 id="3-2-模型理念"><a href="#3-2-模型理念" class="headerlink" title="3.2 模型理念"></a>3.2 模型理念</h3><p>​        <strong>3D face model</strong>：使用一个CNN对输入图像处理，得到${\alpha}, {\beta}, {\delta}, {p}, {\gamma}$等参数，${\alpha}\in{R}^{80},{\beta}\in{R}^{64},{\delta}\in{R}^{80}$。表达式如下所示，最终模型包括36k个顶点：<br>$$<br>S=S(\alpha,\beta)=\bar{S}+B_{id}\alpha+B_{exp}\beta\<br>T=T(\delta)=\bar{T}+B_t\delta<br>$$<br>​       ${S}, {T}$分别表示平均脸的形状和纹理参数，$B_{id}, {B_{exp}}, {B_t}$分别是身份，表情和纹理的PCA基（都经过标准偏差归一化处理）；使用<strong>BFM</strong>预测$\bar{S},B_{id},\bar{T},B_t$，使用<strong>FaceWarehouse</strong>预测$B{exp}$。</p>
<p>​       <strong>Illumination Model</strong>：假设人脸是Lambertian平面，使用球谐函数SH估计场景光照。法向是$n_i$，皮肤纹理是$t_i$的顶点$s_i$辐射度为下式，其中${\phi_b}:R^3\rightarrow{R}$是SH基函数，$\gamma_b$是对应的SH系数，$\gamma\in{R}^9$，$B=3$<br>$$<br>C(n_i,t_i|\gamma)=t_i·{\sum}_{b=1}^{B^2}{\gamma_b}{\phi_b}(n_i)<br>$$<br>​      <strong>Camera Model</strong>：透视投影，3D人脸姿态$p$由旋转$R\in{SO(3)}$和平移$t\in{R^3}$表示。</p>
<p>​      <strong>Summary</strong>：最终预测的向量结果$x=(\alpha,\beta,\delta,\gamma,{p})\in{R^{239}}$，（备注：80+64+80+9+6=239）利用ResNet50来回归预测这239个参数，将ResNet50的最后一层全连接输出改为239，该网络称为R-Net。</p>
<h3 id="3-3-单张图片人脸重建"><a href="#3-3-单张图片人脸重建" class="headerlink" title="3.3 单张图片人脸重建"></a>3.3 单张图片人脸重建</h3><p>​        给定一张RGB图片$I$，作者使用R-Net回归参数向量$x$，根据得到的人脸模型可以渲染得到新的图片$I’$，训练时不需要任何真实标签，而是根据$I’$来计算损失。</p>
<h4 id="3-3-1-Image-Level-Loss"><a href="#3-3-1-Image-Level-Loss" class="headerlink" title="3.3.1 Image-Level Loss"></a>3.3.1 Image-Level Loss</h4><h5 id="3-3-1-1-Robust-Photometric-Loss"><a href="#3-3-1-1-Robust-Photometric-Loss" class="headerlink" title="3.3.1.1 Robust Photometric Loss"></a>3.3.1.1 Robust Photometric Loss</h5><p>​        原始图片和重建图片之间的像素差异作为损失是直观的方法，本文基于此提出了一种鲁棒的、皮肤感知的图像损失：式子定义如下：<br>$$<br>L_{photo}(x)=\frac{\sum_{i\in{M}}A_i·||I_i-I’<em>i(x)||<em>2}{\sum</em>{i\in{M}}A_i}\<br>\A_i=&lt;!–swig￼0–&gt;}</em>{P_i,\quad{otherwise}}}<br>$$<br>​        其中$i$表示像素索引；$M$表示投影的人脸区域；$||·||$表示$l_2$距离；$A$是一个基于皮肤颜色的attention mask，借助在一个皮肤数据集训练好的贝叶斯分类器来预测每个像素$i$上的皮肤颜色概率$P_i$ 。</p>
<h5 id="3-3-1-2-Lamdmark-Loss"><a href="#3-3-1-2-Lamdmark-Loss" class="headerlink" title="3.3.1.2 Lamdmark Loss"></a>3.3.1.2 Lamdmark Loss</h5><p>​        在训练中使用2D图片上的人脸关键点作为弱监督信息，利用sota的3D人脸对齐方法来检测训练图片的68个人脸坐标$q_n$，将重建人脸的3D关键点投影到图像空间得到$q’<em>n$，计算两者的距离作为损失。$w_n$是坐标点权重，经过实验发现在嘴巴内部和鼻子处的权重设为20，其他地方的权重设为1最合适，式子如下。<br>$$<br>L</em>{lan}(x)=\frac{1}{N}{\sum}_{n=1}^{N}w_n||q_n-q’_n(x)||^2<br>$$</p>
<h4 id="3-3-2-Perception-Level-Loss"><a href="#3-3-2-Perception-Level-Loss" class="headerlink" title="3.3.2 Perception-Level Loss"></a>3.3.2 Perception-Level Loss</h4><p>$$<br>L_{per}(x)=1-\frac{&lt;f(I),f(I’(x))&gt;}{||f(I)||·||f(I’(x))||}<br>$$</p>
<h4 id="3-3-3-正则化"><a href="#3-3-3-正则化" class="headerlink" title="3.3.3 正则化"></a>3.3.3 正则化</h4><p>​        为防止人脸形状和纹理退化，使用3DMM系数的正则项：<br>$$<br>L_{coef}(x)=w_{\alpha}||\alpha||^2+w_{\beta}||\beta||^2+w_{\gamma}||\gamma||^2 \<br>w_\alpha=1.0 \quad w_\beta=0.8 \quad w_\gamma=1.7e-3<br>$$<br>​        尽管BFM模型的面部纹理是使用特殊设备获得的，但仍有一些阴影（如环境光遮蔽），为此再添入一个正则项：<br>$$<br>L_{tex}(x)=\sum_{c\in{r,g,b}}var(T_{c,R}(x))<br>$$</p>
<h4 id="3-3-4-损失函数总结"><a href="#3-3-4-损失函数总结" class="headerlink" title="3.3.4 损失函数总结"></a>3.3.4 损失函数总结</h4><p>​        损失函数的总式子如下，其中$w_{photo}=1.9 \quad w_{lan}=1.6e-3 \quad w_{per}=0.2 \quad w_{coef}=3e-4 \quad w_{tex}=5$<br>$$<br>L(x)=w_{photo}L_{photo}(x)+w_{lan}L_{lan}(x)+w_{per}L_{per}(x)+w_{coef}L_{coef}(x)+w_{tex}L_{tex}(x)<br>$$</p>
<h3 id="3-4-多张图片人脸重建"><a href="#3-4-多张图片人脸重建" class="headerlink" title="3.4 多张图片人脸重建"></a>3.4 多张图片人脸重建</h3><p>​        除了从单张人脸图片重建人脸，如何从一个人的多张脸部图片，去重建一个更加精确的人脸模型也是一个很有意义的问题。不同的图片可能采集自不同的姿态、光照等，能够互相提供补充信息，这样重建出来的人脸对于遮挡、不佳的光照等情况更加鲁棒。</p>
<p><img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220429163911623.png" alt="image-20220429163911623"></p>
<p>​        作者从单张图片人脸重建的结果学习一个置信度(反映重建质量)，作者针对人脸形状参数$\alpha\in{R^{80}}$生成一个反映置信度的向量$c\in{R^{80}}$，图片集为$I:={I^j|=j=1,…M}$，最终的人脸形状参数为：<br>$$<br>a_{aggr}=(\sum_{j}c^j\odot\alpha^j)\oslash(\sum_jc^j)\<br>\odot和\oslash分别表示哈达玛积和商<br>$$<br>​        作者提出C-Net来预测置信度$c$，由于R-Net能够预测诸如人脸姿态、光照等高阶信息，很自然地想到将其特征图运用到C-Net中来，作者同时使用了R-Net的浅层和深层特征，如前图所示。为了训练C-Net，首先从一张图片$I^j$得到人脸系数$\hat{x}^j$，$\hat{x}^j=(\alpha_{aggr},\beta^j,\delta^j,\gamma^j,p^j)$，然后生成重建图片$I^{j’}$，C-Net的损失函数如下所示，$L(·)$是前面单张人脸图片重建的损失函数</p>
<p><img src="https://gitee.com/Forever_XS/cloud_img/raw/master/blog/image-20220429153620067.png" alt="image-20220429153620067"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/24/ReviewFaceRecon/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/24/ReviewFaceRecon/" class="post-title-link" itemprop="url">Review Face Reconstruction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-09-24 14:05:05 / Modified: 14:04:08" itemprop="dateCreated datePublished" datetime="2022-09-24T14:05:05+08:00">2022-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Face-Recon/" itemprop="url" rel="index"><span itemprop="name">Face Recon</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">code display</span><br></pre></td></tr></table></figure>

<pre><code>#include&lt;iostream&gt;
#include&lt;vector&gt;
int main()
&#123;
    int x = 666666;
    cout&lt;&lt;x;
    return 0;
&#125;
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://the-fleetinglove.github.io/2022/09/23/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/IMG_0045.jpg">
      <meta itemprop="name" content="XS">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | FleetingSmile Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/09/23/hello-world/" class="post-title-link" itemprop="url">Hello World!!!</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-09-23 10:18:34" itemprop="dateCreated datePublished" datetime="2022-09-23T10:18:34+08:00">2022-09-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-09-24 15:39:40" itemprop="dateModified" datetime="2022-09-24T15:39:40+08:00">2022-09-24</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2022/09/23/hello-world/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">XS</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  





</body>
</html>
